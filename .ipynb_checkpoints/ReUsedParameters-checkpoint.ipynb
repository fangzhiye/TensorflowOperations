{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设你为图片过滤器创建了一个简单的模块，和我们的卷积神经网络教程模块相似,但是这里包括两个卷积（为了简化实例这里只有两个）.如果你仅使用tf.Variable变量,那么你的模块就如怎么使用变量里面所解释的是一样的模块."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_image_filter(input_images):\n",
    "    conv1_weights = tf.Variable(tf.random_normal([5, 5, 32, 32]),\n",
    "        name=\"conv1_weights\")\n",
    "    conv1_biases = tf.Variable(tf.zeros([32]), name=\"conv1_biases\")\n",
    "    conv1 = tf.nn.conv2d(input_images, conv1_weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu1 = tf.nn.relu(conv1 + conv1_biases)\n",
    "\n",
    "    conv2_weights = tf.Variable(tf.random_normal([5, 5, 32, 32]),\n",
    "        name=\"conv2_weights\")\n",
    "    conv2_biases = tf.Variable(tf.zeros([32]), name=\"conv2_biases\")\n",
    "    conv2 = tf.nn.conv2d(relu1, conv2_weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv2 + conv2_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们想重用这个模块时问题还在增多.假设你想把你的图片过滤器运用到两张不同的图片， image1和image2.你想通过拥有同一个参数的同一个过滤器来过滤两张图片，你可以调用my_image_filter()两次，但是这会产生两组变量."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First call creates one set of variables.\n",
    "result1 = my_image_filter(image1)\n",
    "# Another set is created in the second call.\n",
    "result2 = my_image_filter(image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常共享变量的方法就是在单独的代码块中来创建他们并且通过使用他们的函数.如使用字典的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables_dict = {\n",
    "    \"conv1_weights\": tf.Variable(tf.random_normal([5, 5, 32, 32]),\n",
    "        name=\"conv1_weights\")\n",
    "    \"conv1_biases\": tf.Variable(tf.zeros([32]), name=\"conv1_biases\")\n",
    "    ... etc. ...\n",
    "}\n",
    "\n",
    "def my_image_filter(input_images, variables_dict):\n",
    "    conv1 = tf.nn.conv2d(input_images, variables_dict[\"conv1_weights\"],\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu1 = tf.nn.relu(conv1 + variables_dict[\"conv1_biases\"])\n",
    "\n",
    "    conv2 = tf.nn.conv2d(relu1, variables_dict[\"conv2_weights\"],\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv2 + variables_dict[\"conv2_biases\"])\n",
    "\n",
    "# The 2 calls to my_image_filter() now use the same variables\n",
    "result1 = my_image_filter(image1, variables_dict)\n",
    "result2 = my_image_filter(image2, variables_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 变量作用域实例\n",
    "变量作用域机制在TensorFlow中主要由两部分组成：\n",
    "\n",
    "tf.get_variable(<name>, <shape>, <initializer>): 通过所给的名字创建或是返回一个变量.\n",
    "tf.variable_scope(<scope_name>): 通过 tf.get_variable()为变量名指定命名空间.\n",
    "方法 tf.get_variable() 用来获取或创建一个变量，而不是直接调用tf.Variable.它采用的不是像`tf.Variable这样直接获取值来初始化的方法.一个初始化就是一个方法，创建其形状并且为这个形状提供一个张量.这里有一些在TensorFlow中使用的初始化变量：\n",
    "\n",
    "tf.constant_initializer(value) 初始化一切所提供的值,\n",
    "tf.random_uniform_initializer(a, b)从a到b均匀初始化,\n",
    "tf.random_normal_initializer(mean, stddev) 用所给平均值和标准差初始化均匀分布.\n",
    "为了了解tf.get_variable()怎么解决前面所讨论的问题,让我们在单独的方法里面创建一个卷积来重构一下代码，命名为conv_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "        initializer=tf.constant_intializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个方法中用了\"weights\" 和\"biases\"两个简称.而我们更偏向于用conv1 和 conv2这两个变量的写法,但是不同的变量需要不同的名字.这就是tf.variable_scope() 变量起作用的地方.他为变量指定了相应的命名空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5, 5, 32, 32], [32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = my_image_filter(image1)\n",
    "result2 = my_image_filter(image2)\n",
    "# Raises ValueError(... conv1/weights already exists ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就像你看见的一样，tf.get_variable()会检测已经存在的变量是否已经共享.如果你想共享他们，你需要像下面使用的一样，通过reuse_variables()这个方法来指定."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"image_filters\") as scope:\n",
    "    result1 = my_image_filter(image1)\n",
    "    scope.reuse_variables()\n",
    "    result2 = my_image_filter(image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理解 tf.get_variable()\n",
    "为了理解变量作用域，首先完全理解tf.get_variable()是怎么工作的是很有必要的. 通常我们就是这样调用tf.get_variable 的.\n",
    "\n",
    "v = tf.get_variable(name, shape, dtype, initializer)\n",
    "此调用做了有关作用域的两件事中的其中之一，方法调入.总的有两种情况.\n",
    "\n",
    "情况1:当tf.get_variable_scope().reuse == False时，作用域就是为创建新变量所设置的.\n",
    "这种情况下，v将通过tf.Variable所提供的形状和数据类型来重新创建.创建变量的全称将会由当前变量作用域名+所提供的名字所组成,并且还会检查来确保没有任何变量使用这个全称.如果这个全称已经有一个变量使用了，那么方法将会抛出ValueError错误.如果一个变量被创建,他将会用initializer(shape)进行初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "情况1：当tf.get_variable_scope().reuse == True时，作用域是为重用变量所设置\n",
    "这种情况下，调用就会搜索一个已经存在的变量，他的全称和当前变量的作用域名+所提供的名字是否相等.如果不存在相应的变量，就会抛出ValueError 错误.如果变量找到了，就返回这个变量.如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "with tf.variable_scope(\"foo\", reuse=True):\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "assert v1 == v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即使你不能直接设置 reuse 为 False ,但是你可以输入一个重用变量作用域,然后就释放掉,就成为非重用的变量.当打开一个变量作用域时,使用reuse=True 作为参数是可以的.但也要注意，同一个原因，reuse 参数是不可继承.所以当你打开一个重用变量作用域，那么所有的子作用域也将会被重用."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"root\"):\n",
    "    # At start, the scope is not reusing.\n",
    "    assert tf.get_variable_scope().reuse == False\n",
    "    with tf.variable_scope(\"foo\"):\n",
    "        # Opened a sub-scope, still not reusing.\n",
    "        assert tf.get_variable_scope().reuse == False\n",
    "    with tf.variable_scope(\"foo\", reuse=True):\n",
    "        # Explicitly opened a reusing scope.\n",
    "        assert tf.get_variable_scope().reuse == True\n",
    "        with tf.variable_scope(\"bar\"):\n",
    "            # Now sub-scope inherits the reuse flag.\n",
    "            assert tf.get_variable_scope().reuse == True\n",
    "    # Exited the reusing scope, back to a non-reusing one.\n",
    "    assert tf.get_variable_scope().reuse == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的所有例子中，我们共享参数只因为他们的名字是一致的，那是因为我们开启一个变量作用域重用时刚好用了同一个字符串.在更复杂的情况，他可以通过变量作用域对象来使用，而不是通过依赖于右边的名字来使用.为此,变量作用域可以被获取并使用，而不是仅作为当开启一个新的变量作用域的名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\") as foo_scope:\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "with tf.variable_scope(foo_scope)\n",
    "    w = tf.get_variable(\"w\", [1])\n",
    "with tf.variable_scope(foo_scope, reuse=True)\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "    w1 = tf.get_variable(\"w\", [1])\n",
    "assert v1 == v\n",
    "assert w1 == w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当开启一个变量作用域，使用一个预先已经存在的作用域时，我们会跳过当前变量作用域的前缀而直接成为一个完全不同的作用域.这就是我们做得完全独立的地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\") as foo_scope:\n",
    "    assert foo_scope.name == \"foo\"\n",
    "with tf.variable_scope(\"bar\")\n",
    "    with tf.variable_scope(\"baz\") as other_scope:\n",
    "        assert other_scope.name == \"bar/baz\"\n",
    "        with tf.variable_scope(foo_scope) as foo_scope2:\n",
    "            assert foo_scope2.name == \"foo\"  # Not changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用tf.get_variable()允许你重写方法来创建或者重用变量,并且可以被外部透明调用.但是如果我们想改变创建变量的初始化器那要怎么做呢？是否我们需要为所有的创建变量方法传递一个额外的参数呢？那在大多数情况下，当我们想在一个地方并且为所有的方法的所有的变量设置一个默认初始化器，那又改怎么做呢？为了解决这些问题，变量作用域可以携带一个默认的初始化器.他可以被子作用域继承并传递给tf.get_variable() 调用.但是如果其他初始化器被明确地指定,那么他将会被重写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\") as foo_scope:\n",
    "    assert foo_scope.name == \"foo\"\n",
    "with tf.variable_scope(\"bar\")\n",
    "    with tf.variable_scope(\"baz\") as other_scope:\n",
    "        assert other_scope.name == \"bar/baz\"\n",
    "        with tf.variable_scope(foo_scope) as foo_scope2:\n",
    "            assert foo_scope2.name == \"foo\"  # Not changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们讨论 tf.variable_scope 怎么处理变量的名字.但是又是如何在作用域中影响到 其他ops的名字的呢？ops在一个变量作用域的内部创建，那么他应该是共享他的名字，这是很自然的想法.出于这样的原因，当我们用with tf.variable_scope(\"name\")时，这就间接地开启了一个tf.name_scope(\"name\").比如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\"):\n",
    "    x = 1.0 + tf.get_variable(\"v\", [1])\n",
    "assert x.op.name == \"foo/add\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "名称作用域可以被开启并添加到一个变量作用域中,然后他们只会影响到ops的名称,而不会影响到变量."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\"):\n",
    "    with tf.name_scope(\"bar\"):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "        x = 1.0 + v\n",
    "assert v.name == \"foo/v:0\"\n",
    "assert x.op.name == \"foo/bar/add\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
